{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1abf4432",
   "metadata": {
    "papermill": {
     "duration": 0.009269,
     "end_time": "2025-01-26T22:41:58.852490",
     "exception": false,
     "start_time": "2025-01-26T22:41:58.843221",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **üéØ Evaluation Metrics for Regression and Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52bb671",
   "metadata": {
    "papermill": {
     "duration": 0.007178,
     "end_time": "2025-01-26T22:41:58.867055",
     "exception": false,
     "start_time": "2025-01-26T22:41:58.859877",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "BY: **Muhammad Hassan Saboor**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdfefb7",
   "metadata": {
    "papermill": {
     "duration": 0.006463,
     "end_time": "2025-01-26T22:41:58.880953",
     "exception": false,
     "start_time": "2025-01-26T22:41:58.874490",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **üëã Introduction**\n",
    "\n",
    "Evaluation metrics are essential tools for assessing the performance of machine learning models. They help us understand how well a model predicts outcomes, measures errors, and identifies strengths and weaknesses. Different types of metrics are suited for different tasks, such as `classification` and `regression`. Choosing the right metric ensures that the model aligns with the problem's requirements and objectives.\n",
    "\n",
    "This notebook provides a comprehensive guide to the most commonly used evaluation metrics in machine learning. For each metric, you‚Äôll find:\n",
    "\n",
    "- A simple, one-line definition.\n",
    "- The mathematical formula.\n",
    "- A practical example for better understanding.\n",
    "  \n",
    "By the end of this notebook, you'll have a clear understanding of how to evaluate models effectively, interpret results, and select the appropriate metric for your specific machine learning task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc03392b",
   "metadata": {
    "papermill": {
     "duration": 0.006476,
     "end_time": "2025-01-26T22:41:58.894307",
     "exception": false,
     "start_time": "2025-01-26T22:41:58.887831",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> ## First I will tell you what are **True Positive**, **True Negative**, **False Positive**, and **False Negative**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad7da15",
   "metadata": {
    "papermill": {
     "duration": 0.006451,
     "end_time": "2025-01-26T22:41:58.907644",
     "exception": false,
     "start_time": "2025-01-26T22:41:58.901193",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> These are the building blocks of evaluation metrics for binary classification. They arise from comparing predicted labels with actual (ground truth) labels\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4ada07",
   "metadata": {
    "papermill": {
     "duration": 0.006447,
     "end_time": "2025-01-26T22:41:58.920796",
     "exception": false,
     "start_time": "2025-01-26T22:41:58.914349",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**1. True Positive (TP):**\n",
    "\n",
    "**Definition** Those cases where the model correctly predicts the positive class.\n",
    "\n",
    "**Example** The model predicts \"Disease\" (positive), and the person actually has the disease."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aad908c",
   "metadata": {
    "papermill": {
     "duration": 0.00649,
     "end_time": "2025-01-26T22:41:58.934052",
     "exception": false,
     "start_time": "2025-01-26T22:41:58.927562",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**2. True Negative (TN):**\n",
    "\n",
    "**Definition** Those cases where the model correctly predicts the negative class.\n",
    "\n",
    "**Example** The model predicts \"No Disease\" (negative), and the person actually does not have the disease."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b2015e",
   "metadata": {
    "papermill": {
     "duration": 0.006315,
     "end_time": "2025-01-26T22:41:58.947088",
     "exception": false,
     "start_time": "2025-01-26T22:41:58.940773",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**3. False Positive (FP):**\n",
    "\n",
    "**Definition** Those cases where the model predicts the positive class incorrectly.\n",
    "\n",
    "**Example** The model predicts \"Disease\" (positive), but the person does not have the disease (false alarm)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9018cf5f",
   "metadata": {
    "papermill": {
     "duration": 0.006439,
     "end_time": "2025-01-26T22:41:58.960296",
     "exception": false,
     "start_time": "2025-01-26T22:41:58.953857",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**4. False Negative (FN):**\n",
    "\n",
    "**Definition** Those cases where the model predicts the negative class incorrectly.\n",
    "\n",
    "**Example** The model predicts \"No Disease\" (negative), but the person actually has the disease (missed detection)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4dc347",
   "metadata": {
    "papermill": {
     "duration": 0.006511,
     "end_time": "2025-01-26T22:41:58.973675",
     "exception": false,
     "start_time": "2025-01-26T22:41:58.967164",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **Confusion Matrix**\n",
    "\n",
    "| Actual \\ Predicted | Positive (1) | Negative (0) |\n",
    "|--------------------|--------------|--------------|\n",
    "| **Positive (1)**   | True Positive (TP) | False Negative (FN) |\n",
    "| **Negative (0)**   | False Positive (FP) | True Negative (TN) |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a90f5a",
   "metadata": {
    "papermill": {
     "duration": 0.006445,
     "end_time": "2025-01-26T22:41:58.986950",
     "exception": false,
     "start_time": "2025-01-26T22:41:58.980505",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Classification Matrix**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc75f91f",
   "metadata": {
    "papermill": {
     "duration": 0.006541,
     "end_time": "2025-01-26T22:41:59.000437",
     "exception": false,
     "start_time": "2025-01-26T22:41:58.993896",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. **Accuracy**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8019487",
   "metadata": {
    "papermill": {
     "duration": 0.006582,
     "end_time": "2025-01-26T22:41:59.013965",
     "exception": false,
     "start_time": "2025-01-26T22:41:59.007383",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Definition** \n",
    "\n",
    "Accuracy is the percentage of correct predictions made by the model.\n",
    "\n",
    "**Formula** \n",
    "\n",
    "$Accuracy = \\frac{TP + TN}{TP + TN + FP + FN}$\n",
    "\n",
    "**Example**\n",
    "\n",
    "If a model predicts 80 out of 100 test samples correctly (e.g., 50 True Positives + 30 True Negatives), then:\n",
    "\n",
    "$Accuracy = \\frac{50 + 30}{100}$ = 0.8(80%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89b8420",
   "metadata": {
    "papermill": {
     "duration": 0.006491,
     "end_time": "2025-01-26T22:41:59.027378",
     "exception": false,
     "start_time": "2025-01-26T22:41:59.020887",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. **Precision**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647e78ab",
   "metadata": {
    "papermill": {
     "duration": 0.006553,
     "end_time": "2025-01-26T22:41:59.040928",
     "exception": false,
     "start_time": "2025-01-26T22:41:59.034375",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Definition** \n",
    "\n",
    "Precision is the percentage of correctly predicted positive cases out of all cases predicted as positive.\n",
    "\n",
    "**Formula** \n",
    "\n",
    "$Precision = \\frac{TP}{TP + FP}$\n",
    "\n",
    "**Example**\n",
    "\n",
    "If a model predicts 30 positive cases, out of which 25 are correct (True Positives) and 5 are incorrect (False Positives), then:\n",
    "\n",
    "$Precision = \\frac{25}{25 + 5}$ = 0.833(83.3%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f589e9d4",
   "metadata": {
    "papermill": {
     "duration": 0.006464,
     "end_time": "2025-01-26T22:41:59.054288",
     "exception": false,
     "start_time": "2025-01-26T22:41:59.047824",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. **Recall**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8903bd53",
   "metadata": {
    "papermill": {
     "duration": 0.006582,
     "end_time": "2025-01-26T22:41:59.068170",
     "exception": false,
     "start_time": "2025-01-26T22:41:59.061588",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Definition** \n",
    "\n",
    "Recall is the percentage of correctly predicted positive cases out of all actual positive cases.\n",
    "\n",
    "**Formula** \n",
    "\n",
    "$Recall = \\frac{TP}{TP + FN}$\n",
    "\n",
    "**Example**\n",
    "\n",
    "If there are 40 actual positive cases in the data, and the model correctly identifies 30 of them (True Positives) but misses 10 (False Negatives), then:\n",
    "\n",
    "$Recall = \\frac{30}{30 + 10}$ = 0.75(75%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d96983c",
   "metadata": {
    "papermill": {
     "duration": 0.006636,
     "end_time": "2025-01-26T22:41:59.081797",
     "exception": false,
     "start_time": "2025-01-26T22:41:59.075161",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. **F1-score**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e20e3b",
   "metadata": {
    "papermill": {
     "duration": 0.006491,
     "end_time": "2025-01-26T22:41:59.095336",
     "exception": false,
     "start_time": "2025-01-26T22:41:59.088845",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Definition** \n",
    "\n",
    "F1-Score is the harmonic mean of Precision and Recall, balancing their trade-off.\n",
    "\n",
    "**Formula** \n",
    "\n",
    "$F1score = 2. \\frac{Precision * Recall}{Precision + Recall}$\n",
    "\n",
    "**Example**\n",
    "\n",
    "If a model has a Precision of 80% (0.8) and Recall of 70% (0.7), then:\n",
    "\n",
    "$F1score = 2. \\frac{0.8 * 0.7}{0.8 + 0.7}$ = 0.7467(74.67%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b977aefb",
   "metadata": {
    "papermill": {
     "duration": 0.006429,
     "end_time": "2025-01-26T22:41:59.108623",
     "exception": false,
     "start_time": "2025-01-26T22:41:59.102194",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5. **ROC (Receiver Operating Characteristic)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9205f3",
   "metadata": {
    "papermill": {
     "duration": 0.006674,
     "end_time": "2025-01-26T22:41:59.122240",
     "exception": false,
     "start_time": "2025-01-26T22:41:59.115566",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Definition** \n",
    "\n",
    "ROC is a curve that shows the trade-off between True Positive Rate (Recall) and False Positive Rate at different classification thresholds.\n",
    "\n",
    "**Formula (True Positive Rate (TPR) or Recall)** \n",
    "\n",
    "$TPR = \\frac{TP}{TP + FN}$\n",
    "\n",
    "**Formula (False Positive Rate (FPR))** \n",
    "\n",
    "$FPR = \\frac{FP}{FP + TN}$\n",
    "\n",
    "**Example**\n",
    "\n",
    "For different thresholds, we calculate TPR and FPR and plot them on the ROC curve. A model with a better performance has an ROC curve closer to the top-left corner (high TPR, low FPR)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6ff82b",
   "metadata": {
    "papermill": {
     "duration": 0.006625,
     "end_time": "2025-01-26T22:41:59.135913",
     "exception": false,
     "start_time": "2025-01-26T22:41:59.129288",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 6. **AUC (Area Under the Curve)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71260b6",
   "metadata": {
    "papermill": {
     "duration": 0.00658,
     "end_time": "2025-01-26T22:41:59.149383",
     "exception": false,
     "start_time": "2025-01-26T22:41:59.142803",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Definition** \n",
    "\n",
    "AUC is the area under the ROC curve. It represents the likelihood that the model will correctly distinguish between a randomly chosen positive and negative instance.\n",
    "\n",
    "**Formula**\n",
    "\n",
    "- The AUC value is the area under the ROC curve, typically computed using numerical integration methods.\n",
    "- **AUC ranges from 0 to 1, where:**\n",
    "  \n",
    "    - 0.5 indicates no discriminative power (random guessing).\n",
    "    - 1 indicates perfect classification.\n",
    "\n",
    "\n",
    "**Example**\n",
    "\n",
    "If a model's ROC curve shows an AUC of 0.85, it means that there is an 85% chance that the model will correctly classify a randomly chosen positive instance as more likely to be positive than a randomly chosen negative instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71218c66",
   "metadata": {
    "papermill": {
     "duration": 0.006736,
     "end_time": "2025-01-26T22:41:59.163174",
     "exception": false,
     "start_time": "2025-01-26T22:41:59.156438",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 7. **Log Loss (Logarithmic Loss or Cross-Entropy Loss)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f655ace",
   "metadata": {
    "papermill": {
     "duration": 0.006543,
     "end_time": "2025-01-26T22:41:59.176695",
     "exception": false,
     "start_time": "2025-01-26T22:41:59.170152",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Definition** \n",
    "\n",
    "Log Loss measures the accuracy of a classifier by comparing the predicted probabilities to the actual class labels. It penalizes wrong predictions, especially when the model is confident but incorrect.\n",
    "\n",
    "**Formula** \n",
    "\n",
    "$$\n",
    "\\text{Log Loss} = - \\frac{1}{N} \\sum_{i=1}^{N} \\left( y_i \\log(p_i) + (1 - y_i) \\log(1 - p_i) \\right)\n",
    "$$\n",
    "\n",
    "\n",
    "**Where**\n",
    "  \n",
    "  - N is the number of instances\n",
    "  - yi is the true label (0 or 1).\n",
    "  - pi is the predicted probability of the positive class.\n",
    "\n",
    "**Example**\n",
    "\n",
    "For different thresholds, we calculate TPR and FPR and plot them on the ROC curve. A model with a better performance has an ROC curve closer to the top-left corner (high TPR, low FPR)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5340d85c",
   "metadata": {
    "papermill": {
     "duration": 0.007275,
     "end_time": "2025-01-26T22:41:59.190938",
     "exception": false,
     "start_time": "2025-01-26T22:41:59.183663",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Definition** \n",
    "\n",
    "Log Loss measures the accuracy of a classifier by comparing the predicted probabilities to the actual class labels. It penalizes wrong predictions, especially when the model is confident but incorrect.\n",
    "\n",
    "**Formula** \n",
    "\n",
    "$$\n",
    "\\text{Log Loss} = - \\frac{1}{N} \\sum_{i=1}^{N} \\left( y_i \\log(p_i) + (1 - y_i) \\log(1 - p_i) \\right)\n",
    "$$\n",
    "\n",
    "\n",
    "**Where**\n",
    "  \n",
    "  - $N$ is the number of data points.\n",
    "  - $y_i$ is the true label (0 or 1).\n",
    "  - $pi$ is the predicted probability of the positive class.\n",
    "\n",
    "**Example**\n",
    "\n",
    "- If the model predicts a probability of 0.9 for a positive class and the actual label is 1, the Log Loss will be:\n",
    "  \n",
    "$$\n",
    "\\text{Log Loss} = -\\log(0.9) \\approx 0.105\n",
    "$$\n",
    "\n",
    "\n",
    "- If the model predicts 0.1 for the same positive class (but the true label is 1), the Log Loss would be much higher:\n",
    "\n",
    "\n",
    "$$\n",
    "\\text{Log Loss} = -\\log(0.1) \\approx 2.302\n",
    "$$\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107cf094",
   "metadata": {
    "papermill": {
     "duration": 0.006545,
     "end_time": "2025-01-26T22:41:59.204490",
     "exception": false,
     "start_time": "2025-01-26T22:41:59.197945",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 8. **Specificity (True Negative Rate)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5573e7",
   "metadata": {
    "papermill": {
     "duration": 0.006694,
     "end_time": "2025-01-26T22:41:59.218079",
     "exception": false,
     "start_time": "2025-01-26T22:41:59.211385",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Definition** \n",
    "\n",
    "Specificity is the percentage of correctly predicted negative cases out of all actual negative cases. It measures the model's ability to identify negative class instances.\n",
    "\n",
    "**Formula** \n",
    "\n",
    "$Specificity = \\frac{TN}{TN + FP}$\n",
    "\n",
    "**Example**\n",
    "\n",
    "If there are 50 actual negative cases, and the model correctly identifies 40 of them as negative (True Negatives) but misclassifies 10 as positive (False Positives), then:\n",
    "\n",
    "$Specificity = \\frac{40}{40 + 10}$ = 0.8(80%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff09e1f",
   "metadata": {
    "papermill": {
     "duration": 0.00657,
     "end_time": "2025-01-26T22:41:59.231516",
     "exception": false,
     "start_time": "2025-01-26T22:41:59.224946",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 9. **MCC (Matthews Correlation Coefficient)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414bd390",
   "metadata": {
    "papermill": {
     "duration": 0.006613,
     "end_time": "2025-01-26T22:41:59.245069",
     "exception": false,
     "start_time": "2025-01-26T22:41:59.238456",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Definition** \n",
    "\n",
    "MCC is a metric that measures the quality of binary classifications by considering all four confusion matrix elements (TP, TN, FP, FN). It provides a balanced measure even in imbalanced datasets.\n",
    "\n",
    "**Formula** \n",
    "\n",
    "$$\n",
    "MCC = \\frac{TP * TN - FP * FN}{\\sqrt{(TP + FP)(TP + FN)(TN + FP)(TN + FN)}}\n",
    "$$\n",
    "\n",
    "**Example**\n",
    "\n",
    "- If the confusion matrix values are:\n",
    "  - TP = 50, TN = 30, FP = 10, FN = 10\n",
    "- The MCC would be:\n",
    "  \n",
    "$$\n",
    "MCC = \\frac{50 \\times 30 - 10 \\times 10}{\\sqrt{(50 + 10)(50 + 10)(30 + 10)(30 + 10)}} = \\frac{1400}{2400} \\approx 0.5833\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d400211f",
   "metadata": {
    "papermill": {
     "duration": 0.007624,
     "end_time": "2025-01-26T22:41:59.259843",
     "exception": false,
     "start_time": "2025-01-26T22:41:59.252219",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 10. **Confusion Matrix**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7e643c",
   "metadata": {
    "papermill": {
     "duration": 0.006468,
     "end_time": "2025-01-26T22:41:59.273288",
     "exception": false,
     "start_time": "2025-01-26T22:41:59.266820",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Definition**\n",
    "\n",
    "A confusion matrix is a table used to evaluate the performance of a classification model by comparing its predicted labels with the actual labels. It shows how many instances were correctly or incorrectly classified into each category.\n",
    "\n",
    "**Formula**\n",
    "\n",
    "A confusion matrix for binary classification contains four key elements:\n",
    "\n",
    "| Actual \\ Predicted | Positive (1) | Negative (0) |\n",
    "|--------------------|--------------|--------------|\n",
    "| Positive (1)       | True Positive (TP)  | False Negative (FN) |\n",
    "| Negative (0)       | False Positive (FP) | True Negative (TN) |\n",
    "\n",
    "- **True Positives (TP):** Correctly predicted positive cases.\n",
    "- **True Negatives (TN):** Correctly predicted negative cases.\n",
    "- **False Positives (FP):** Incorrectly predicted positive cases (Type I error).\n",
    "- **False Negatives (FN):** Incorrectly predicted negative cases (Type II error).\n",
    "\n",
    "**Example**\n",
    "  > For a binary classifier:\n",
    "  - TP = 50, TN = 30, FP = 10, FN = 10\n",
    "  The confusion matrix would look like this:\n",
    "\n",
    "| Actual \\ Predicted | Positive (1) | Negative (0) |\n",
    "|--------------------|--------------|--------------|\n",
    "| Positive (1)       | 50           | 10           |\n",
    "| Negative (0)       | 10           | 30           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fadea37",
   "metadata": {
    "papermill": {
     "duration": 0.006679,
     "end_time": "2025-01-26T22:41:59.287047",
     "exception": false,
     "start_time": "2025-01-26T22:41:59.280368",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Regression Matrix**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9b81f8",
   "metadata": {
    "papermill": {
     "duration": 0.006544,
     "end_time": "2025-01-26T22:41:59.300407",
     "exception": false,
     "start_time": "2025-01-26T22:41:59.293863",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. **MAE (Mean Absolute Error)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77e6030",
   "metadata": {
    "papermill": {
     "duration": 0.006657,
     "end_time": "2025-01-26T22:41:59.313978",
     "exception": false,
     "start_time": "2025-01-26T22:41:59.307321",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Definition**\n",
    "\n",
    "MAE is the average of the absolute differences between predicted values and actual values. It gives an idea of how far off the predictions are, on average.\n",
    "\n",
    "**Formula**\n",
    "\n",
    "$$\n",
    "MAE = \\frac{1}{N} \\sum_{i=1}^{N} \\left| y_i - \\hat{y}_i \\right|\n",
    "$$\n",
    "\n",
    "**Where**\n",
    "\n",
    "- $N$ is the number of data points.\n",
    "- $y_i$ is the actual value.\n",
    "- $\\hat{y}_i$ is the predicted value.\n",
    "\n",
    "**Example**\n",
    "\n",
    "If you have a set of predictions [3,5,7] and actual values [4,5,8], then:\n",
    "\n",
    "$$\n",
    "MAE = \\frac{1}{3} \\left( |3 - 4| + |5 - 5| + |7 - 8| \\right) = \\frac{1}{3} \\left( 1 + 0 + 1 \\right) = 0.67\n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65732474",
   "metadata": {
    "papermill": {
     "duration": 0.00654,
     "end_time": "2025-01-26T22:41:59.327381",
     "exception": false,
     "start_time": "2025-01-26T22:41:59.320841",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. **MSE (Mean Squared Error)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6d0e3d",
   "metadata": {
    "papermill": {
     "duration": 0.00676,
     "end_time": "2025-01-26T22:41:59.341028",
     "exception": false,
     "start_time": "2025-01-26T22:41:59.334268",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Definition**\n",
    "\n",
    "MSE is the average of the squared differences between predicted values and actual values. It gives a higher penalty to larger errors due to the squaring of differences.\n",
    "\n",
    "**Formula**\n",
    "\n",
    "$$\n",
    "MSE = \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "**Where**\n",
    "\n",
    "- $N$ is the number of data points.\n",
    "- $y_i$ is the actual value.\n",
    "- $\\hat{y}_i$ is the predicted value.\n",
    "  \n",
    "**Example**\n",
    "\n",
    "If you have a set of predictions [3,5,7] and actual values [4,5,8], then:\n",
    "\n",
    "$$\n",
    "MSE = \\frac{1}{3} \\left( (3 - 4)^2 + (5 - 5)^2 + (7 - 8)^2 \\right) = \\frac{1}{3} \\left( 1 + 0 + 1 \\right) = 0.67\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c828c5ea",
   "metadata": {
    "papermill": {
     "duration": 0.006577,
     "end_time": "2025-01-26T22:41:59.354490",
     "exception": false,
     "start_time": "2025-01-26T22:41:59.347913",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. **RMSE (Root Mean Squared Error)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4dc509",
   "metadata": {
    "papermill": {
     "duration": 0.006572,
     "end_time": "2025-01-26T22:41:59.367945",
     "exception": false,
     "start_time": "2025-01-26T22:41:59.361373",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Definition**\n",
    "\n",
    "RMSE is the square root of the average of the squared differences between predicted values and actual values. It provides a measure of error in the same units as the data, making it easier to interpret than MSE.\n",
    "\n",
    "**Formula**\n",
    "\n",
    "$$\n",
    "RMSE = \\sqrt{\\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2}\n",
    "$$\n",
    "\n",
    "**Where**\n",
    "\n",
    "- $N$ is the number of data points.\n",
    "- $y_i$ is the actual value.\n",
    "- $\\hat{y}_i$ is the predicted value.\n",
    "\n",
    "**Example**\n",
    "\n",
    "If you have a set of predictions [3,5,7] and actual values [4,5,8], then:\n",
    "\n",
    "$$\n",
    "RMSE = \\sqrt{\\frac{1}{3} \\left( (3 - 4)^2 + (5 - 5)^2 + (7 - 8)^2 \\right)} = \\sqrt{\\frac{1}{3} \\left( 1 + 0 + 1 \\right)} = \\sqrt{\\frac{2}{3}} \\approx 0.82\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1214c48",
   "metadata": {
    "papermill": {
     "duration": 0.006986,
     "end_time": "2025-01-26T22:41:59.381967",
     "exception": false,
     "start_time": "2025-01-26T22:41:59.374981",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. **MAPE (Mean Absolute Percentage Error)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a77a98",
   "metadata": {
    "papermill": {
     "duration": 0.006551,
     "end_time": "2025-01-26T22:41:59.395467",
     "exception": false,
     "start_time": "2025-01-26T22:41:59.388916",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Definition**\n",
    "\n",
    "MAPE is the average of the absolute percentage differences between predicted values and actual values. It expresses the error as a percentage, making it easy to understand in relative terms.\n",
    "\n",
    "**Formula**\n",
    "\n",
    "$$\n",
    "MAPE = \\frac{1}{N} \\sum_{i=1}^{N} \\frac{|y_i - \\hat{y}_i|}{y_i} \\times 100\n",
    "$$\n",
    "\n",
    "**Where**\n",
    "\n",
    "- $N$ is the number of data points.\n",
    "- $y_i$ is the actual value.\n",
    "- $\\hat{y}_i$ is the predicted value.\n",
    "\n",
    "**Example**\n",
    "\n",
    "If you have a set of predictions [3,5,7] and actual values [4,5,8], then:\n",
    "\n",
    "$$\n",
    "MAPE = \\frac{1}{3} \\left( \\frac{|3 - 4|}{4} + \\frac{|5 - 5|}{5} + \\frac{|7 - 8|}{8} \\right) \\times 100 = \\frac{1}{3} \\left( 0.25 + 0 + 0.125 \\right) \\times 100 = 12.5\\%\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b365dd60",
   "metadata": {
    "papermill": {
     "duration": 0.006495,
     "end_time": "2025-01-26T22:41:59.408919",
     "exception": false,
     "start_time": "2025-01-26T22:41:59.402424",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5. **R-squared (Coefficient of Determination)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4341c2",
   "metadata": {
    "papermill": {
     "duration": 0.00658,
     "end_time": "2025-01-26T22:41:59.422535",
     "exception": false,
     "start_time": "2025-01-26T22:41:59.415955",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Definition**\n",
    "\n",
    "R-squared measures the proportion of the variance in the dependent variable that is predictable from the independent variables. It indicates how well the model's predictions match the actual data.\n",
    "\n",
    "**Formula**\n",
    "\n",
    "$$\n",
    "R^2 = 1 - \\frac{\\sum_{i=1}^{N} (y_i - \\bar{y})^2}{\\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2}\n",
    "$$\n",
    "\n",
    "**Where**\n",
    "\n",
    "- $N$ is the number of data points.\n",
    "- $y_i$ is the actual value.\n",
    "- $\\hat{y}_i$ is the predicted value.\n",
    "- $\\bar{y}_i$ is the predicted value.\n",
    "\n",
    "**Example**\n",
    "\n",
    "If the total variance of actual values is 100, and the residual sum of squares is 25, then:\n",
    "\n",
    "$$\n",
    "R^2 = 1 - \\frac{100}{25} = 0.75\n",
    "$$\n",
    "\n",
    "This means 75% of the variance in the data is explained by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b947b01",
   "metadata": {
    "papermill": {
     "duration": 0.006583,
     "end_time": "2025-01-26T22:41:59.436154",
     "exception": false,
     "start_time": "2025-01-26T22:41:59.429571",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 6. **Adjusted R-squared**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83e4639",
   "metadata": {
    "papermill": {
     "duration": 0.006711,
     "end_time": "2025-01-26T22:41:59.449839",
     "exception": false,
     "start_time": "2025-01-26T22:41:59.443128",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Definition**\n",
    "\n",
    "Adjusted R-squared is a modified version of R-squared that adjusts for the number of predictors in the model. It penalizes the addition of irrelevant predictors and is more useful when comparing models with different numbers of features.\n",
    "\n",
    "**Formula**\n",
    "\n",
    "$$\n",
    "\\text{Adjusted } R^2 = 1 - \\left( \\frac{(1 - R^2) \\times (N - 1)}{(N - p -1)} \\right) \n",
    "$$\n",
    "\n",
    "**Where**\n",
    "\n",
    "- $R^2$ is the R-squared value.\n",
    "- $N$ is the number of data points.\n",
    "- $p$ is the number of predictors (features) in the model.\n",
    "\n",
    "**Example**\n",
    "\n",
    "If $R^2$ = 0.80, $N$ = 100, and $p$ = 5, then:\n",
    "\n",
    "$$\n",
    "\\text{Adjusted } R^2 = 1 - \\left( \\frac{(1 - 0.80) \\times (100 - 1)}{(100 - 5 - 1)} \\right)  = 1 - \\left( \\frac{(0.20 \\times 99)}{94} \\right) \\approx 0.781\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1070e4",
   "metadata": {
    "papermill": {
     "duration": 0.006784,
     "end_time": "2025-01-26T22:41:59.463783",
     "exception": false,
     "start_time": "2025-01-26T22:41:59.456999",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 7. **Adjusted R-squared**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f75939",
   "metadata": {
    "papermill": {
     "duration": 0.006524,
     "end_time": "2025-01-26T22:41:59.477407",
     "exception": false,
     "start_time": "2025-01-26T22:41:59.470883",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Definition**\n",
    "\n",
    "Huber Loss is a combination of Mean Squared Error (MSE) and Mean Absolute Error (MAE). It is less sensitive to outliers than MSE and provides a smoother penalty for large errors compared to MAE. It is commonly used in regression tasks where the data contains outliers.\n",
    "\n",
    "**Formula**\n",
    "\n",
    "$$\n",
    "L_{\\delta}(y, \\hat{y}) =\n",
    "\\begin{cases}\n",
    "\\frac{1}{2} (y - \\hat{y})^2 & \\text{for } |y - \\hat{y}| \\leq \\delta \\\\\n",
    "\\delta |y - \\hat{y}| - \\frac{1}{2} \\delta^2 & \\text{for } |y - \\hat{y}| > \\delta\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "**Where**\n",
    "\n",
    "- $y$ is the actual value.\n",
    "- $\\hat{y}_i$ is the predicted value.\n",
    "- $Œ¥$ is a hyperparameter that determines the threshold for switching between squared loss and absolute loss.\n",
    "\n",
    "**Example**\n",
    "\n",
    "For \\( Œ¥ = 1 \\), actual value \\( y = 5 \\), and predicted value \\( $\\hat{y}$ = 7  \\):\n",
    "\n",
    "Since \\( |5 - 7| = 2 > 1 \\), the loss would be calculated as:\n",
    "\n",
    "$$\n",
    "L_{1}(5, 7) = 1 \\times |5 - 7| - \\frac{1}{2} \\times 1^2 = 2 - 0.5 = 1.5\n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d633f04b",
   "metadata": {
    "papermill": {
     "duration": 0.006635,
     "end_time": "2025-01-26T22:41:59.491032",
     "exception": false,
     "start_time": "2025-01-26T22:41:59.484397",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 8. **MBD (Mean Bias Deviation)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a759c2f",
   "metadata": {
    "papermill": {
     "duration": 0.006898,
     "end_time": "2025-01-26T22:41:59.504961",
     "exception": false,
     "start_time": "2025-01-26T22:41:59.498063",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Definition**\n",
    "\n",
    "MBD is a metric that measures the average difference between the predicted values and actual values. It indicates whether the model tends to overestimate or underestimate the predictions. Positive MBD values suggest overestimation, while negative values suggest underestimation.\n",
    "\n",
    "**Formula**\n",
    "\n",
    "$$\n",
    "\\text{MBD} = \\frac{1}{N} \\sum_{i=1}^{N} (\\hat{y}_i - y_i)\n",
    "$$\n",
    "\n",
    "**Where**\n",
    "\n",
    "- $N$ is the number of data points.\n",
    "- $\\hat{y}_i$ is the predicted value.\n",
    "- ${y}_i$ is the actual value.\n",
    "\n",
    "**Example**\n",
    "\n",
    "If you have a set of predictions [3,5,7] and actual values [4,5,8], then:\n",
    "\n",
    "$$\n",
    "\\text{MBD} = \\frac{1}{3} \\left( (3 - 4) + (5 - 5) + (7 - 8) \\right) = \\frac{1}{3} (-1 + 0 - 1) = -0.67\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e4f8ba",
   "metadata": {
    "papermill": {
     "duration": 0.006674,
     "end_time": "2025-01-26T22:41:59.518791",
     "exception": false,
     "start_time": "2025-01-26T22:41:59.512117",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Thank You!**\n",
    "\n",
    "Thank you for exploring this notebook on evaluation metrics for machine learning! üåü Your interest in understanding these concepts is a step forward in building better, more reliable models. I hope this guide has provided clarity and helped you grasp the importance and usage of various metrics for both `regression` and `classification` tasks.\n",
    "\n",
    "Feel free to reach out with feedback, suggestions, or any questions. \n",
    "\n",
    "üí¨ Keep experimenting, keep learning, and keep building amazing projects! üöÄ\n",
    "\n",
    "Happy coding! üñ•Ô∏è‚ú®"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3.736257,
   "end_time": "2025-01-26T22:41:59.944698",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-26T22:41:56.208441",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
