{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# üß† **VAE vs GAN vs Diffusion: Image Generation Showdown** üöÄ\n\nGenerative models are at the heart of modern **Deep Learning** and **Generative AI**, powering applications such as image synthesis, data augmentation, and creative AI systems.\n\nIn this notebook, we perform a **hands-on and fair comparison** of three popular generative modeling approaches:\n\n- **Variational AutoEncoder (VAE)**\n- **Generative Adversarial Network (GAN)**\n- **Diffusion Model**\n\nAll models are trained on the **MNIST handwritten digit dataset** using the **same data source and similar constraints** to ensure a meaningful comparison.\n\n---\n\n## üéØ **Objectives of This Notebook**\n\n- Train **VAE, GAN, and Diffusion models** on MNIST\n- Generate handwritten digits (0‚Äì9) using each approach\n- Visually compare **generation quality and stability**\n- Observe and analyze **training behavior**\n- Highlight **strengths and limitations** of each model\n\n---\n\n## üß© **Why This Comparison Matters**\n\nEach generative model follows a **fundamentally different learning philosophy**:\n\n- **VAE** learns a structured latent space through probabilistic encoding  \n- **GAN** learns via adversarial competition between generator and discriminator  \n- **Diffusion models** generate data by gradually denoising random noise  \n\nUnderstanding these differences is essential for anyone working in **Deep Learning, Computer Vision, or Generative AI**.\n\n---\n\n## üìå **Note**\nThis notebook focuses on **conceptual clarity and educational insight** rather than state-of-the-art performance.  \nModels are trained for a limited number of epochs to clearly demonstrate learning behavior and outputs.\n\n---\n\nLet‚Äôs dive in and explore how these generative models compare! üîç‚ú®","metadata":{}},{"cell_type":"markdown","source":"# **üß± Imports & Setup**","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-27T18:19:12.248880Z","iopub.execute_input":"2026-01-27T18:19:12.249092Z","iopub.status.idle":"2026-01-27T18:19:12.254891Z","shell.execute_reply.started":"2026-01-27T18:19:12.249070Z","shell.execute_reply":"2026-01-27T18:19:12.253844Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# üß± **Dataset (Same for All Models)**","metadata":{}},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])\n\ndataset = datasets.MNIST(\n    root=\"./data\",\n    train=True,\n    transform=transform,\n    download=True\n)\n\nloader = DataLoader(dataset, batch_size=128, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-27T18:20:00.044622Z","iopub.execute_input":"2026-01-27T18:20:00.044937Z","iopub.status.idle":"2026-01-27T18:20:01.834084Z","shell.execute_reply.started":"2026-01-27T18:20:00.044913Z","shell.execute_reply":"2026-01-27T18:20:01.833170Z"}},"outputs":[{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9.91M/9.91M [00:00<00:00, 41.8MB/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28.9k/28.9k [00:00<00:00, 1.18MB/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.65M/1.65M [00:00<00:00, 10.6MB/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.54k/4.54k [00:00<00:00, 6.53MB/s]\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# **üß† Variational Autoencoder (VAE)**","metadata":{}},{"cell_type":"markdown","source":"### **Model**","metadata":{}},{"cell_type":"code","source":"class VAE(nn.Module):\n    def __init__(self, latent_dim=20):\n        super().__init__()\n        self.fc1 = nn.Linear(784, 400)\n        self.fc_mu = nn.Linear(400, latent_dim)\n        self.fc_logvar = nn.Linear(400, latent_dim)\n        self.fc2 = nn.Linear(latent_dim, 400)\n        self.fc3 = nn.Linear(400, 784)\n\n    def encode(self, x):\n        h = torch.relu(self.fc1(x))\n        return self.fc_mu(h), self.fc_logvar(h)\n\n    def reparameterize(self, mu, logvar):\n        std = torch.exp(0.5 * logvar)\n        eps = torch.randn_like(std)\n        return mu + eps * std\n\n    def decode(self, z):\n        h = torch.relu(self.fc2(z))\n        return torch.tanh(self.fc3(h))\n\n    def forward(self, x):\n        mu, logvar = self.encode(x)\n        z = self.reparameterize(mu, logvar)\n        return self.decode(z), mu, logvar","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-27T18:20:32.330994Z","iopub.execute_input":"2026-01-27T18:20:32.331601Z","iopub.status.idle":"2026-01-27T18:20:32.338139Z","shell.execute_reply.started":"2026-01-27T18:20:32.331567Z","shell.execute_reply":"2026-01-27T18:20:32.337477Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"### **Training**","metadata":{}},{"cell_type":"code","source":"vae = VAE(latent_dim=20).to(device)\noptimizer = optim.Adam(vae.parameters(), lr=1e-3)\n\ndef vae_loss(recon_x, x, mu, logvar):\n    recon = nn.functional.mse_loss(recon_x, x, reduction='sum')\n    kl = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n    return recon + kl\n\nfor epoch in range(5):\n    for x, _ in loader:\n        x = x.view(-1, 784).to(device)\n        recon, mu, logvar = vae(x)\n        loss = vae_loss(recon, x, mu, logvar)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    print(f\"VAE Epoch {epoch+1} | Loss: {loss.item():.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-27T18:21:24.232965Z","iopub.execute_input":"2026-01-27T18:21:24.233246Z","iopub.status.idle":"2026-01-27T18:22:26.210845Z","shell.execute_reply.started":"2026-01-27T18:21:24.233221Z","shell.execute_reply":"2026-01-27T18:22:26.210225Z"}},"outputs":[{"name":"stdout","text":"VAE Epoch 1 | Loss: 8430.38\nVAE Epoch 2 | Loss: 6913.21\nVAE Epoch 3 | Loss: 7440.52\nVAE Epoch 4 | Loss: 7208.06\nVAE Epoch 5 | Loss: 6782.68\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# üß† **GAN**","metadata":{}},{"cell_type":"markdown","source":"### **Model**","metadata":{}},{"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self, latent_dim=20):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(latent_dim, 256),\n            nn.ReLU(),\n            nn.Linear(256, 784),\n            nn.Tanh()\n        )\n\n    def forward(self, z):\n        return self.net(z)\n\n\nclass Discriminator(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(784, 256),\n            nn.LeakyReLU(0.2),\n            nn.Linear(256, 1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        return self.net(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-27T18:22:50.144618Z","iopub.execute_input":"2026-01-27T18:22:50.144932Z","iopub.status.idle":"2026-01-27T18:22:50.150911Z","shell.execute_reply.started":"2026-01-27T18:22:50.144907Z","shell.execute_reply":"2026-01-27T18:22:50.150141Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"### **Training**","metadata":{}},{"cell_type":"code","source":"G = Generator().to(device)\nD = Discriminator().to(device)\n\nopt_G = optim.Adam(G.parameters(), lr=2e-4)\nopt_D = optim.Adam(D.parameters(), lr=2e-4)\ncriterion = nn.BCELoss()\n\nfor epoch in range(5):\n    for x, _ in loader:\n        x = x.view(-1, 784).to(device)\n        bs = x.size(0)\n\n        # Train Discriminator\n        z = torch.randn(bs, 20).to(device)\n        fake = G(z)\n\n        real_loss = criterion(D(x), torch.ones(bs, 1).to(device))\n        fake_loss = criterion(D(fake.detach()), torch.zeros(bs, 1).to(device))\n        d_loss = real_loss + fake_loss\n\n        opt_D.zero_grad()\n        d_loss.backward()\n        opt_D.step()\n\n        # Train Generator\n        g_loss = criterion(D(fake), torch.ones(bs, 1).to(device))\n        opt_G.zero_grad()\n        g_loss.backward()\n        opt_G.step()\n\n    print(f\"GAN Epoch {epoch+1} | D Loss: {d_loss.item():.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-27T18:23:09.429901Z","iopub.execute_input":"2026-01-27T18:23:09.430183Z","iopub.status.idle":"2026-01-27T18:24:12.998572Z","shell.execute_reply.started":"2026-01-27T18:23:09.430160Z","shell.execute_reply":"2026-01-27T18:24:12.997898Z"}},"outputs":[{"name":"stdout","text":"GAN Epoch 1 | D Loss: 0.76\nGAN Epoch 2 | D Loss: 0.69\nGAN Epoch 3 | D Loss: 0.50\nGAN Epoch 4 | D Loss: 0.99\nGAN Epoch 5 | D Loss: 0.63\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# **üß† Diffusion Model (Simplified)**","metadata":{}},{"cell_type":"markdown","source":"### **‚ö†Ô∏è Educational lightweight diffusion (gold-friendly)**","metadata":{}},{"cell_type":"code","source":"class SimpleDiffusion(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(784, 512),\n            nn.ReLU(),\n            nn.Linear(512, 784)\n        )\n\n    def forward(self, x):\n        return self.net(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-27T18:24:36.126488Z","iopub.execute_input":"2026-01-27T18:24:36.126765Z","iopub.status.idle":"2026-01-27T18:24:36.131913Z","shell.execute_reply.started":"2026-01-27T18:24:36.126742Z","shell.execute_reply":"2026-01-27T18:24:36.131174Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"### **Training**","metadata":{}},{"cell_type":"code","source":"diffusion = SimpleDiffusion().to(device)\noptimizer = optim.Adam(diffusion.parameters(), lr=1e-3)\n\nfor epoch in range(5):\n    for x, _ in loader:\n        x = x.view(-1, 784).to(device)\n        noise = torch.randn_like(x)\n        noisy_x = x + noise\n\n        pred_noise = diffusion(noisy_x)\n        loss = nn.functional.mse_loss(pred_noise, noise)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    print(f\"Diffusion Epoch {epoch+1} | Loss: {loss.item():.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-27T18:25:13.340802Z","iopub.execute_input":"2026-01-27T18:25:13.341262Z","iopub.status.idle":"2026-01-27T18:26:11.622880Z","shell.execute_reply.started":"2026-01-27T18:25:13.341234Z","shell.execute_reply":"2026-01-27T18:26:11.622165Z"}},"outputs":[{"name":"stdout","text":"Diffusion Epoch 1 | Loss: 0.9566\nDiffusion Epoch 2 | Loss: 0.9424\nDiffusion Epoch 3 | Loss: 0.9408\nDiffusion Epoch 4 | Loss: 0.9306\nDiffusion Epoch 5 | Loss: 0.9241\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"# **üîç Training Behavior Observations**\n\n- **VAE loss** shows a general downward trend with minor fluctuations due to the KL-divergence term.\n- **GAN discriminator loss** oscillates, which is expected and indicates adversarial balance.\n- **Diffusion loss** decreases slowly and steadily, reflecting stable noise prediction.\n\n> These behaviors align with the theoretical training dynamics of each generative model.\n","metadata":{}}]}